[{"categories":null,"content":"","keywords":null,"title":"big data, spark","uri":"https://rhcode.github.io/categories/big-data-spark/"},{"categories":null,"content":"","keywords":null,"title":"Categories","uri":"https://rhcode.github.io/categories/"},{"categories":["big data, spark"],"content":"Following are a some thoughts I have jotted down to help write Spark jobs that are faster and less prone to issues like Out of Memory errors -\nUnderstand your data Get a good understanding about your data before you set about writing any set of transformations and actions on it. By understanding your data, I mean the following -\n What is the size of your data? Is there any skew in your data?","keywords":null,"title":"Making Spark Jobs Faster and Error Free","uri":"https://rhcode.github.io/posts/making-spark-jobs-faster-error-free/"},{"categories":null,"content":"","keywords":null,"title":"Posts","uri":"https://rhcode.github.io/posts/"},{"categories":null,"content":"","keywords":null,"title":"Rohan Honwade","uri":"https://rhcode.github.io/"},{"categories":["security"],"content":"I recently had the opportunity to change the password hashing algorithm we used in one of our services. In this post, we briefly compare the older SHA-256 algorithm with a more modern implementation that is Argon2id. I will shed some light on some statistics you can use to make the right choice of parameters for the Argon2 algorithm with respect to memory cost and compute cost. I have also shared the code snippet I used to carry out my research spike.","keywords":null,"title":"Argon2 Password Hashing","uri":"https://rhcode.github.io/posts/argon-password-hashing/"},{"categories":null,"content":"","keywords":null,"title":"security","uri":"https://rhcode.github.io/categories/security/"},{"categories":null,"content":"","keywords":null,"title":"Tags","uri":"https://rhcode.github.io/tags/"}]